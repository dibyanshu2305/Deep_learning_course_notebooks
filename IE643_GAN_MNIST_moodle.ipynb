{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dibyanshu2305/Deep_learning_course_notebooks/blob/main/IE643_GAN_MNIST_moodle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR0XGtZ18MK6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "#  if device_name != '/device:GPU:0':\n",
        "#    raise SystemError('GPU device not found')\n",
        "#  print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8WAzZejekY-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as opt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5MHSronekZB"
      },
      "outputs": [],
      "source": [
        "mb_size = 64   #Mini-batch size\n",
        "\n",
        "def get_indices(dataset):\n",
        "    indices =  []\n",
        "    for i in range(len(dataset.targets)):  #use train_labels if error with tragets\n",
        "        if dataset.targets[i] == 2 or dataset.targets[i] == 4 or dataset.targets[i] == 6:\n",
        "            indices.append(i)   #indices of data with labels 2, 4 or 6\n",
        "    return indices\n",
        "\n",
        "trainData = torchvision.datasets.MNIST('./data/', download=True, transform=transforms.ToTensor(), train=True)\n",
        "\n",
        "idx = get_indices(trainData)\n",
        "print(len(idx))\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(trainData,batch_size=mb_size, \n",
        "                                          sampler = torch.utils.data.sampler.SubsetRandomSampler(idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf6SJjPBekZD"
      },
      "outputs": [],
      "source": [
        "# No. of training data = 17718"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gWjqwKXekZD"
      },
      "outputs": [],
      "source": [
        "dataIter = iter(trainLoader)\n",
        "\n",
        "imgs, labels = dataIter.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcH_huhRekZD"
      },
      "outputs": [],
      "source": [
        "imgs.shape  #shape of the tensor data obtained from the train loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHePyF9lekZE"
      },
      "outputs": [],
      "source": [
        "#visualization of data on a grid\n",
        "def imshow(imgs):\n",
        "    imgs = torchvision.utils.make_grid(imgs)\n",
        "    npimgs = imgs.numpy()\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(np.transpose(npimgs, (1,2,0)), cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_GqNOSZekZE"
      },
      "outputs": [],
      "source": [
        "imshow(imgs) #using imshow() to obtain the grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0482WuLwekZE"
      },
      "source": [
        "![Generative Adversarial Network](https://www.kdnuggets.com/wp-content/uploads/generative-adversarial-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WVmT5lEekZG"
      },
      "outputs": [],
      "source": [
        "Z_dim = 100  #size of the generated data\n",
        "H_dim = 128  #no. of hidden neurons\n",
        "X_dim = imgs.view(imgs.size(0), -1).size(1) #output neurons to generate an image\n",
        "\n",
        "print(Z_dim, H_dim, X_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxYoWauWekZH"
      },
      "outputs": [],
      "source": [
        "#neural network for generative network\n",
        "class Gen(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(Z_dim, H_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(H_dim, X_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "          \n",
        "    def forward(self, input):\n",
        "        return self.model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDMRl4FuekZI"
      },
      "outputs": [],
      "source": [
        "G = Gen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XYt_774ekZI"
      },
      "outputs": [],
      "source": [
        "#neural network for discriminative model\n",
        "class Dis(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(X_dim, H_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(H_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return self.model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBUd7YRLekZJ"
      },
      "outputs": [],
      "source": [
        "D = Dis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVzPNENYekZJ"
      },
      "outputs": [],
      "source": [
        "#print the network architecture\n",
        "print(G)\n",
        "print(D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-2LV2vqekZK"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3  #learning rate\n",
        "#optimizers for both models\n",
        "g_opt = opt.Adam(G.parameters(), lr=lr)\n",
        "d_opt = opt.Adam(D.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    G_loss_run = 0.0\n",
        "    D_loss_run = 0.0\n",
        "    \n",
        "    for i, data in enumerate(trainLoader):\n",
        "        X, _ = data\n",
        "        X = X.view(X.size(0), -1)\n",
        "        mb_size = X.size(0)\n",
        "        \n",
        "        one_labels = torch.ones(mb_size, 1)\n",
        "        zero_labels = torch.zeros(mb_size, 1)\n",
        "        \n",
        "        z = torch.randn(mb_size, Z_dim)\n",
        "        \n",
        "        D_real = D(X)\n",
        "        D_fake = D(G(z))\n",
        "        \n",
        "        D_real_loss = F.binary_cross_entropy(D_real, one_labels)  #loss -(1/m)(log D(x))\n",
        "        D_fake_loss = F.binary_cross_entropy(D_fake, zero_labels)  #loss -(1/m)(log(1-D(G(z))))\n",
        "        D_loss = D_real_loss + D_fake_loss\n",
        "        \n",
        "        d_opt.zero_grad()\n",
        "        D_loss.backward()\n",
        "        d_opt.step()\n",
        "        \n",
        "        z = torch.randn(mb_size, Z_dim)\n",
        "        \n",
        "        D_fake = D(G(z))\n",
        "        G_loss = F.binary_cross_entropy(D_fake, one_labels)  #loss -(1/m)(log (1-D(G(z))))\n",
        "        \n",
        "        g_opt.zero_grad()\n",
        "        G_loss.backward()\n",
        "        g_opt.step()\n",
        "        \n",
        "        G_loss_run += G_loss.item()\n",
        "        D_loss_run += D_loss.item()\n",
        "        \n",
        "    print('Epoch:{},   G_loss:{},    D_loss:{}'.format(epoch, G_loss_run/(i+1), D_loss_run/(i+1)))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        samples = G(z).detach()\n",
        "        samples = samples.view(samples.size(0), 1, 28, 28)\n",
        "        imshow(samples)"
      ],
      "metadata": {
        "id": "wlYZoO0zJVAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}